## Exploration

### Recap
- Bandits
    - Can apply Hoeffding and Union bounds to measure confidence in current konwledge about each arm (action)
- Rmax
    - "Optimism in the face of uncertainty"
    - Assumes unexplored actions produce some maximum possible reward, which encourages exploration via greedy action selection
    - "Grass is always greener..."
- Bandits + Rmax = stochastic + sequential 
- KWIK